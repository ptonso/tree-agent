{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, Tuple\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wm-1step\n",
      "blind-ac\n",
      "wm-5step\n",
      "cnn\n",
      "cnn_1\n",
      "lower\n",
      "low\n",
      "small\n",
      "high\n",
      "large\n",
      "high_1\n",
      "vae\n",
      "vae_1\n",
      "td\n",
      "td_1\n",
      "triplet\n",
      "large_1\n",
      "return\n",
      "agressive\n",
      "high_2\n",
      "td_2\n",
      "td_3\n",
      "reward\n",
      "kl\n",
      "uniform-policy\n",
      "mvp\n",
      "lower_1\n",
      "low_1\n",
      "small_1\n",
      "high_3\n",
      "large_2\n",
      "high_4\n"
     ]
    }
   ],
   "source": [
    "experiments_path = \"experiments/\"\n",
    "\n",
    "# json_path : json_data\n",
    "json_data : Dict[str, Dict] = {}\n",
    "\n",
    "for root, _, files in os.walk(experiments_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    json_data[file_path] = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Warning: Failed to parse {file_path}\")\n",
    "\n",
    "\n",
    "json_paths = json_data.keys()\n",
    "\n",
    "# unique_exp_name : json_path\n",
    "exp_index : Dict[str, str] = {}\n",
    "\n",
    "for path in json_paths:\n",
    "    basename = path.split(\"/\")[-1]\n",
    "    exp_name = basename.split(\"_\")[0]\n",
    "    if exp_name not in exp_index.keys():\n",
    "        exp_index[exp_name] = path\n",
    "    else:\n",
    "        count = 1\n",
    "        new_exp_name = f\"{exp_name}_{count}\"\n",
    "        while new_exp_name in exp_index:\n",
    "            count += 1\n",
    "            new_exp_name = f\"{exp_name}_{count}\"\n",
    "        exp_index[new_exp_name] = file_path\n",
    "\n",
    "for exp_name, _ in exp_index.items():\n",
    "    print(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected time series data for 19 experiments.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "timeseries_data : Dict[str, Tuple[np.ndarray]] = {}\n",
    "for exp_name, path in exp_index.items():\n",
    "    try:\n",
    "        avg_reward = np.array(json_data[path][\"performance\"][\"avg_rewards\"], dtype=np.float32)\n",
    "        std_reward = np.array(json_data[path][\"performance\"][\"std_rewards\"], dtype=np.float32)\n",
    "        timeseries_data[path] = (avg_reward, std_reward)\n",
    "    except KeyError:\n",
    "        print(f\"Warning: Missing keys in {path}\")\n",
    "\n",
    "print(f\"Collected time series data for {len(timeseries_data)} experiments.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m norm\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstattools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m adfuller\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mStationarityAnalyzer\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "class StationarityAnalyzer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        avg_reward: np.ndarray,\n",
    "        std_reward: np.ndarray,\n",
    "        n: int = 3,\n",
    "        window_size: int = 10,\n",
    "        threshold: float = 0.05,\n",
    "        alpha: float = 0.05,\n",
    "        ):\n",
    "        self.avg_reward = avg_reward\n",
    "        self.std_reward = std_reward\n",
    "        self.n = n\n",
    "        self.window_size = window_size\n",
    "        self.threshold = threshold\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self._stationary_index = -1 # Default is not achieving stationarity\n",
    "\n",
    "\n",
    "        self._perform_analysis()\n",
    "\n",
    "    def _moving_average(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute moving average with given window size.\"\"\"\n",
    "        return np.convolve(data, np.ones(self.window_size) / self.window_size, mode='valid')\n",
    "    \n",
    "    def _moving_variance(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute moving variance with given window_size.\"\"\"\n",
    "        return self._moving_average(data**2) - self._moving_average(data)**2\n",
    "\n",
    "    def _confidence_width(self) -> np.ndarray:\n",
    "        \"\"\"Compute confidence interval width for each time step.\n",
    "        Assumes Gaussian distribution approximation.\"\"\"\n",
    "        return (1.96 * self.std_reward) / np.sqrt(self.n)\n",
    "    \n",
    "    def _geweke_test(self, first_frac: float = 0.1, last_frac: float = 0.5):\n",
    "        \"\"\"Perform geweke test for compare early and late parts of the series.\"\"\"\n",
    "        N = len(self.avg_reward)\n",
    "        first_segment = self.avg_reward[:int(N * first_frac)]\n",
    "        last_segment = self.avg_reward[int(N * (1 - last_frac)):]\n",
    "\n",
    "        mean_first, mean_last = np.mean(first_segment), np.mean(last_segment)\n",
    "        var_first = np.var(first_segment, ddof=1) / len(first_segment)\n",
    "        var_last = np.var(last_segment, ddof=1) / len(last_segment)\n",
    "\n",
    "        z_score = (mean_first - mean_last) / np.sqrt(var_first + var_last)\n",
    "        p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
    "\n",
    "        return p_value > self.alpha # Accept stationarity if p > alpha\n",
    "    \n",
    "    def _adf_test(self):\n",
    "        \"\"\"Perform Augmented Dickey-Fuller test to check for stationarity.\"\"\"\n",
    "        adf_result = adfuller(self.avg_reward, autolag='AIC')\n",
    "        return adf_result[1] < self.alpha # Stationarity if p < alpha\n",
    "\n",
    "\n",
    "    def _perform_analysis(self):\n",
    "        \"\"\"\n",
    "        Perform stationarity analysis by checking stability of mean, variance, and confidence interval.\n",
    "        \"\"\"\n",
    "        moving_avg = self._moving_average(self.avg_reward)\n",
    "        moving_var = self._moving_variance(self.avg_reward)\n",
    "        conf_interval = self._confidence_width()\n",
    "\n",
    "        for t in range(len(moving_avg) - 1):\n",
    "            mean_change = np.abs(moving_avg[t + 1] - moving_avg[t])\n",
    "            var_change = np.abs(moving_var[t + 1] - moving_var[t])\n",
    "\n",
    "            ci_change = np.abs(conf_interval[t + 1] - conf_interval[t])\n",
    "\n",
    "            geweke_result = self._geweke_test()\n",
    "\n",
    "            adf_result = self._adf_test()\n",
    "\n",
    "            if (\n",
    "                mean_change < self.threshold and\n",
    "                var_change < self.threshold and \n",
    "                ci_change < self.threshold and\n",
    "                geweke_result and\n",
    "                adf_result\n",
    "            ):\n",
    "                self._stationary_index = t + self.window_size\n",
    "                return\n",
    "            \n",
    "    @property\n",
    "    def stationarity(self) -> int:\n",
    "        \"\"\"Return index where time series achieves stationrity.\n",
    "        If stationarity is never reached, return -1\"\"\"\n",
    "        return self._stationary_index\n",
    "\n",
    "\n",
    "avg_r, std_r = timeseries_data[exp_index[\"vae\"]]\n",
    "n = 3\n",
    "window_size = 10\n",
    "threhsold = 0.05\n",
    "\n",
    "analyzer = StationarityAnalyzer(avg_r, std_r, n=n, window_size=window_size, threshold=threhsold)\n",
    "\n",
    "print(\"Stationarity Index:\", analyzer.stationarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1722139382.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    which python\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
